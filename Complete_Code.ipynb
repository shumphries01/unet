{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "#from dilateModel import *\n",
    "#from model_edge import *\n",
    "from data import *\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import argparse\n",
    "import imutils\n",
    "\n",
    "from skimage.data import camera\n",
    "from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "import skimage.feature\n",
    "import skimage.viewer\n",
    "import sys\n",
    "\n",
    "from skimage import transform\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with Data Generator; Augment Data with Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "myGene = trainGenerator(8,'/data/spacenet/bldg/AllTrain','PAN-PNG','GT-PNG',data_gen_args,save_to_dir = None)\n",
    "model = unet()\n",
    "model_checkpoint = ModelCheckpoint('unet_membrane_AllTrain_8.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "model.fit_generator(myGene,steps_per_epoch=50,epochs=10,callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Weights to Prepare Model for Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.load_weights(\"Humphries_Bragg_Weights.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Helper Functions to Reshape Image Before Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predImgGen(imgPath, target_size=(256,256)):\n",
    "    img = io.imread(imgPath,as_gray = True)\n",
    "    img = img / 255\n",
    "    img = trans.resize(img,target_size)\n",
    "    img = np.reshape(img,img.shape+(1,))\n",
    "    img = np.reshape(img,(1,)+img.shape)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Loop: Walk through Test Folder, reshape image, make prediction, threshold image, overlay prediction on original. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### maskImg: image of just predicted masks\n",
    "\n",
    "#### maskImgRe: larger image of predicted masks\n",
    "\n",
    "#### PANImg: original image\n",
    "\n",
    "#### comp: combined image with predictions overlayed over original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskImg_List = []\n",
    "test_dir = '/data/spacenet/bldg/AllTest/PAN-PNG'\n",
    "for i,j,k in os.walk(test_dir):\n",
    "    for file in k:\n",
    "        if (os.path.splitext(file)[1] == '.png'):\n",
    "            PANImgPath = os.path.join(test_dir, file)\n",
    "            testImg = predImgGen(PANImgPath)\n",
    "            pred = model.predict(testImg)\n",
    "        \n",
    "            predRe = pred.reshape(256,256)\n",
    "            maskArrThresh = np.zeros((predRe.shape[0], predRe.shape[1], 4)) \n",
    "            maskArrThresh[:,:, 0] = 50\n",
    "            maskArrThresh[:,:, 1] = 255\n",
    "            maskArrThresh[:,:, 2] = 0\n",
    "            for row in range(0, predRe.shape[0]):\n",
    "                for col in range(0, predRe.shape[1]):\n",
    "                    maskArrThresh[row, col, 3] = 255 - int(predRe[row, col] * 255)\n",
    "            maskArrThresh = maskArrThresh.astype(\"uint8\")\n",
    "            maskImg = Image.fromarray(maskArrThresh, 'RGBA')\n",
    "            #maskImg_List += [maskImg]\n",
    "            maskImg.save(file)\n",
    "        \n",
    "            PANImg = Image.open(PANImgPath)\n",
    "            PANImgT = PANImg.convert('RGBA')\n",
    "        \n",
    "            PANDim = (PANImgT.width, PANImgT.height)\n",
    "            maskImgRe = maskImg.resize(PANDim) \n",
    "        \n",
    "            comp = Image.alpha_composite(PANImgT, maskImgRe)\n",
    "            #comp.save(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Center Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize prediction (maskImgRe) to prepare for inversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_image1 = np.array(maskImgRe).astype('float32')/255\n",
    "np_image1 = transform.resize(np_image1, (256, 256, 1))\n",
    "np_image1 = np.expand_dims(np_image1, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invert image; this is necessary in order to use findContours function (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invert1 = cv2.bitwise_not(np_image1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save image to 'data' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveResult(\"data\",invert1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Image for findContours: Load the image, convert it to grayscale, blur it slightly, and threshold it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image, convert it to grayscale, blur it slightly,\n",
    "# and threshold it\n",
    "#image = cv2.imread(\"PAN_AOI_2_Vegas_img1016.png\")\n",
    "image = cv2.imread('0_predict.png')\n",
    "#print('shape={}'.format(image.shape))\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "thresh = cv2.threshold(blurred, 230, 255, cv2.THRESH_BINARY)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display pre-processed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(thresh)\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and show original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#real_image = cv2.imread('/data/spacenet/bldg/AllTest/PAN-PNG/PAN_AOI_5_Khartoum_img1001.png')\n",
    "real_image = cv2.imread('/data/spacenet/bldg/AllTest/PAN-PNG/PAN_AOI_2_Vegas_img1016.png')\n",
    "real_image = cv2.resize(real_image, (256,256))\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(real_image)\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours in the thresholded image\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "#cnts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw Contours on Real Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cnt = cv2.drawContours(real_image, cnts, -1, (0, 255, 0), 2)\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(img_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find and Label Center Points for each Contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the contours\n",
    "plt.figure(figsize = (10,10))\n",
    "i=1\n",
    "for c in cnts:\n",
    "    # compute the center of the contour\n",
    "    M = cv2.moments(c)\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    # draw the contour and center of the shape on the image\n",
    "    #cv2.drawContours(real_image, [c], -1, (0, 255, 0), 2)\n",
    "    #cv2.circle(real_image, (cX, cY), 2, (255, 255, 255), -1)\n",
    "    cv2.putText(real_image, str(i), (cX, cY),cv2.FONT_HERSHEY_SIMPLEX, 0.2, (255, 255, 255), 0)\n",
    "    # show the image\n",
    "    plt.imshow(real_image)\n",
    "    cv2.waitKey(0)\n",
    "    i+=1\n",
    "# plt.imshow(image)\n",
    "# plt.xticks([]), plt.yticks([])\n",
    "# plt.show()\n",
    "#saveResult(\"data/membrane/test2\",image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
